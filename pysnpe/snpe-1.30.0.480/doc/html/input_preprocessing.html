<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-->
<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"></meta>
<meta http-equiv="X-UA-Compatible" content="IE=9"></meta>
<title>Snapdragon Neural Processing Engine SDK: Image Preprocessing</title>
<link href="tabs.css" rel="stylesheet" type="text/css"></link>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="autoEnterCurrentDate.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="is.css" rel="stylesheet" type="text/css" ></link>
<link href="custom.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Snapdragon Neural Processing Engine SDK
   <span id="projectnumber"></span></div>
   <div id="projectbrief">Reference Guide</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('input_preprocessing.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Image Preprocessing </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>SNPE provides support for common image preprocessing operations such as color space conversion (e.g. NV21 to BGR format), scaling, cropping and mean subtraction on all supported runtimes. These operations are added as layers to the network and are performed as part of the forward propagate pipeline. Any data required for the operation, such as a mean image, is embedded into the network DLC.</p>
<p>These image preprocessing operations are currently only supported for DLC networks converted from a Caffe model.</p>
<h1><a class="anchor" id="input_preprocessing_order"></a>
Order of Operations</h1>
<p>The image preprocessing operations are added to the network in a predefined order. This order is fixed and independent of the order in which the options are specified in the converter or in the network prototxt file.</p>
<p>The order of image preprocessing operations is: </p><ul>
<li>
<a class="el" href="input_preprocessing.html#input_preprocessing_encoding">Color space conversion</a> </li>
<li>
<a class="el" href="input_preprocessing.html#input_preprocessing_scaling">Scaling</a> </li>
<li>
<a class="el" href="input_preprocessing.html#input_preprocessing_cropping">Cropping</a> </li>
<li>
<a class="el" href="input_preprocessing.html#input_preprocessing_meansub">Mean Subtraction</a> </li>
</ul>
<h1><a class="anchor" id="input_preprocessing_all"></a>
Supported Operations</h1>
<h2><a class="anchor" id="input_preprocessing_encoding"></a>
Image Color Space Conversion</h2>
<p>SNPE supports converting input images of various pixel formats to BGR, the format required by Caffe networks.</p>
<p>This operation is added by specifying the input image pixel format option to the <a class="el" href="tools.html#tools_snpe-caffe-to-dlc">snpe-caffe-to-dlc</a> conversion tool.</p>
<p>The following source encoding formats are supported:</p>
<p><b>NV21</b></p>
<p>NV21 is the Android version of YUV, also known as YUV420SP. The Chrominance is down sampled and has a sub sampling ratio of 4:2:0. Note that this image format has 3 channels, but the U and V channels are subsampled. For every four Y pixels there is one U and one V pixel.</p>
<p>SNPE supports the JPEG File Interchange Format's YUV pixel specification. The equations governing conversion between BGR and YUV pixels are given at <a href="https://en.wikipedia.org/wiki/YCbCr#JPEG_conversion">https://en.wikipedia.org/wiki/YCbCr#JPEG_conversion</a></p>
<p><b>ARGB32</b></p>
<p>The ARGB32 format consists of 4 bytes per pixel: one byte for Red, one for Green, one for Blue and one for the alpha channel. The alpha channel is ignored. For little endian CPUs, the byte order is BGRA. For big endian CPUs, the byte order is ARGB.</p>
<p><b>RGBA</b></p>
<p>The RGBA format consists of 4 bytes per pixel: one byte for Red, one for Green, one for Blue and one for the alpha channel. The alpha channel is ignored. The byte ordering is endian independent and is always RGBA byte order.</p>
<p><b>BGR</b></p>
<p>The BGR format consists of 3 bytes per pixel: one byte for Red, one for Green and one for Blue. The byte ordering is endian independent and is always BGR byte order.</p>
<h3><a class="anchor" id="input_preprocessing_encoding_example"></a>
Image Color Space Conversion Example</h3>
<p>The following prototxt and converter options describe a network where an input image of size 256x256 in the NV21 format is converted to an image also of size 256x256 in BGR format.</p>
<pre class="fragment">layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 3 dim: 256 dim: 256 } }
}
</pre><pre class="fragment">snpe-caffe-to-dlc --input_network net.prototxt --input_encoding "data" nv21 --output_path net.dlc
snpe-dlc-info -i net.dlc
</pre><p>The output from snpe-dlc-info verifies the details of this encoding conversion: </p><pre class="fragment">--------------------------------------------------------------------------------
| Id | Name | Type | Inputs | Outputs | Out Dims    | Parameters               |
--------------------------------------------------------------------------------
| 0  | data | data | data   | data    | 1x256x256x3 | input_encoding_in: nv21  |
|    |      |      |        |         |             | input_encoding_out: bgr  |
|    |      |      |        |         |             | input_type: image        |
</pre><h2><a class="anchor" id="input_preprocessing_scaling"></a>
Image Scaling</h2>
<p>SNPE supports scaling the input image size as a preprocessing operation. The interpolation algorithm is Unit Square Bilinear. See <a href="https://en.wikipedia.org/wiki/Bilinear_interpolation#Unit_Square">https://en.wikipedia.org/wiki/Bilinear_interpolation#Unit_Square</a> for more details.</p>
<p>This operation is added by specifying the input size option to the snpe-caffe-to-dlc conversion tool. The source image size is specified to the converter, while the target image size is determined from the input layer in the network prototxt. See <a class="el" href="tools.html#tools_snpe-caffe-to-dlc">snpe-caffe-to-dlc</a> for details about this option.</p>
<h3><a class="anchor" id="input_preprocessing_scaling_example"></a>
Image Scaling Example</h3>
<p>The following prototxt and converter options describe a network where an input image of size 256x256 in the BGR encoding is scaled to a size 227x227 also in BGR encoding.</p>
<pre class="fragment">layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 3 dim: 227 dim: 227 } }
}
</pre><pre class="fragment">snpe-caffe-to-dlc --input_network net.prototxt --input_size 256 256 --output_path net.dlc
snpe-dlc-info -i net.dlc
</pre><p>The output from snpe-dlc-info verifies the details of this input image scaling: </p><pre class="fragment">-------------------------------------------------------------------------------------------------------
| Id | Name       | Type    | Inputs | Outputs    | Out Dims    | Parameters                          |
-------------------------------------------------------------------------------------------------------
| 0  | data       | data    | data   | data       | 1x256x256x3 | input_preprocessing: passthrough    |
|    |            |         |        |            |             | input_type: default                 |
| 1  | data_scale | scaling | data   | data_scale | 1x227x227x3 | pad_value: 0                        |
|    |            |         |        |            |             | maintain_aspect_ratio: 0            |
|    |            |         |        |            |             | input_dim: [1, 256, 256, 3]         |
|    |            |         |        |            |             | output_dim: [1, 227, 227, 3]        |
</pre><h2><a class="anchor" id="input_preprocessing_cropping"></a>
Image Cropping</h2>
<p>SNPE supports cropping of input image size as a preprocessing operation. The cropped image is extracted from the center of the source image.</p>
<p>This operation is added by modifying the network prototxt. To specify a crop operation, add a <em>transform_param</em> block with a crop_size option to the Input layer in the network prototxt. Caffe's Input layer does not support cropping, and this transform parameter is meaningless to Caffe. However, snpe-caffe-to-dlc will read this parameter and add a preprocessing image cropping layer to the DLC file. The source image size is taken from the input_param shape and the destination or cropped image size is taken from the transform_param block.</p>
<p>The modification to the network prototxt resembles: </p><pre class="fragment">layer {
  ...
  type: "Input"
  input_param { shape: { &lt;source image dimensions&gt; } }
  transform_param { crop_size: &lt;cropped image dimensions&gt; }
}</pre><h3><a class="anchor" id="input_preprocessing_cropping_example"></a>
Image Cropping Example</h3>
<p>The following prototxt and converter options describe a network where an input image of size 256x256 in the BGR encoding is center cropped to a size 227x227 also in BGR encoding.</p>
<pre class="fragment">layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 3 dim: 256 dim: 256 } }
  transform_param { crop_size: 227 }
}
</pre><pre class="fragment">snpe-caffe-to-dlc --input_network net.prototxt --output_path net.dlc
snpe-dlc-info -i net.dlc
</pre><p>The output from snpe-dlc-info verifies the details of this input image cropping: </p><pre class="fragment">-----------------------------------------------------------------------------------------------
| Id | Name      | Type | Inputs | Outputs   | Out Dims    | Parameters                       |
-----------------------------------------------------------------------------------------------
| 0  | data      | data | data   | data      | 1x256x256x3 | input_preprocessing: passthrough |
|    |           |      |        |           |             | input_type: default              |
| 1  | data_crop | crop | data   | data_crop | 1x227x227x3 | offsets[0]: 0                    |
|    |           |      |        |           |             | offsets[1]: 14                   |
|    |           |      |        |           |             | offsets[2]: 14                   |
|    |           |      |        |           |             | offsets[3]: 0                    |
</pre><h2><a class="anchor" id="input_preprocessing_meansub"></a>
Image Mean Subtraction</h2>
<p>SNPE supports image mean subtraction as a preprocessing operation. As with Caffe, SNPE supports both a mean image file in Caffe's binaryproto format, and also mean subtraction with constant channel values. Note that only one of these operations can be specified for a network.</p>
<p><b>Mean Subtraction With Mean Image</b></p>
<p>This operation is added by modifying the network prototxt. To specify an image mean subtraction, add a <em>transform_param</em> block with mean_file option to the Input layer in the network prototxt. As in Caffe, the mean file must be a binaryproto file. This file is usually generated during database creation in Caffe. Note that the path to mean file must be an absolute path.</p>
<p>Caffe's Input layer does not support mean subtraction, and this transform parameter is meaningless to Caffe. However, snpe-caffe-to-dlc will read this parameter and add a preprocessing mean subtraction layer to the DLC file.</p>
<p>Additionally, SNPE supports specifying a mean image that is larger than the input image size. In this case SNPE will use a center-crop from the mean image to do the mean subtraction.</p>
<p>The modification to the network prototxt resembles: </p><pre class="fragment">layer {
  ...
  type: "Input"
  ...
  transform_param {
    mean_file: "&lt;absolute path to binaryproto file&gt;"
  }
}
</pre><p><b>Mean Subtraction With Channel Values</b></p>
<p>This operation is added by modifying the network prototxt. To specify a constant channel mean subtraction, add a <em>transform_param</em> block with mean_value options to the Input layer in the network prototxt. As in Caffe, the order of the mean values is blue channel, then green channel, then red channel.</p>
<p>Caffe's Input layer does not support mean subtraction, and this transform parameter is meaningless to Caffe. However, snpe-caffe-to-dlc will read this parameter and add a preprocessing mean subtraction layer to the DLC file.</p>
<p>The modification to the network prototxt resembles: </p><pre class="fragment">layer {
  ...
  type: "Input"
  ...
  transform_param {
    mean_value: &lt;blue value&gt;
    mean_value: &lt;green value&gt;
    mean_value: &lt;red value&gt;
  }
}
</pre><h3><a class="anchor" id="input_preprocessing_meansub_examples"></a>
Image Mean Subtraction Examples</h3>
<p><b>Mean Subtraction With Mean Image</b></p>
<p>The following prototxt and converter options describe a network where a mean image is subtracted from the input image of size 256x256.</p>
<pre class="fragment">layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 3 dim: 256 dim: 256 } }
  transform_param {
    mean_file: "/absolute/path/to/net.binaryproto"
  }
}
</pre><pre class="fragment">snpe-caffe-to-dlc --input_network net.prototxt --output_path net.dlc
snpe-dlc-info -i net.dlc
</pre><p>The output from snpe-dlc-info verifies the details of this mean subtraction operation: </p><pre class="fragment">--------------------------------------------------------------------------------------------------------------------------
| Id | Name               | Type          | Inputs | Outputs            | Out Dims    | Parameters                       |
--------------------------------------------------------------------------------------------------------------------------
| 0  | data               | data          | data   | data               | 1x256x256x3 | input_preprocessing: passthrough |
|    |                    |               |        |                    |             | input_type: default              |
| 1  | data_subtract_mean | subtract_mean | data   | data_subtract_mean | 1x256x256x3 |                                  |
</pre><p><b>Mean Subtraction With Channel Values</b></p>
<p>The following prototxt and converter options describe a network where constant channel values are subtracted from an input image of size 256x256. A value of 104 is subtracted from the blue channel, 117 from the green channel, and 123 from the red channel.</p>
<pre class="fragment">layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 3 dim: 256 dim: 256 } }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
}
</pre><pre class="fragment">snpe-caffe-to-dlc --input_network net.prototxt --output_path net.dlc
snpe-dlc-info -i net.dlc
</pre><p>The output from snpe-dlc-info verifies the details of this mean subtraction operation: </p><pre class="fragment">--------------------------------------------------------------------------------------------------------------------------
| Id | Name               | Type          | Inputs | Outputs            | Out Dims  | Parameters                         |
--------------------------------------------------------------------------------------------------------------------------
| 0  | data               | data          | data   | data               | 1x256x256x3 | input_preprocessing: passthrough |
|    |                    |               |        |                    |           | input_type: default                |
| 1  | data_subtract_mean | subtract_mean | data   | data_subtract_mean | 1x256x256x3 |                                  |
</pre><h1><a class="anchor" id="input_preprocessing_chaining"></a>
Multiple Preprocessing Operations Example</h1>
<p>Image preprocessing operations can be chained in the order described above.</p>
<p>The following prototxt and converter options describe a network where the following preprocessing operations occur in order: </p><ol>
<li>
A NV21 image of size 800x600 is converted to a BGR image of size 800x600 </li>
<li>
The 800x600 BGR image is scaled down to a 227x227 BGR image </li>
<li>
Constant channel values are subtracted from the 227x227 BGR image. A value of 104 is subtracted from the blue channel, 117 from the green channel, and 123 from the red channel.  </li>
</ol>
<pre class="fragment">layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 3 dim: 227 dim: 227 } }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
}
</pre><pre class="fragment">snpe-caffe-to-dlc --input_network net.prototxt --input_encoding "data" nv21 --input_size 800 600 --output_path net.dlc
snpe-dlc-info -i net.dlc
</pre><p>The output from snpe-dlc-info verifies the details of these chained preprocessing operations: </p><pre class="fragment">--------------------------------------------------------------------------------------------------------------------------
| Id | Name               | Type          | Inputs     | Outputs            | Out Dims    | Parameters                   |
--------------------------------------------------------------------------------------------------------------------------
| 0  | data               | data          | data       | data               | 1x600x800x3 | input_encoding_in: nv21      |
|    |                    |               |            |                    |             | input_encoding_out: bgr      |
|    |                    |               |            |                    |             | input_type: image            |
| 1  | data_scale         | scaling       | data       | data_scale         | 1x227x227x3 | pad_value: 0                 |
|    |                    |               |            |                    |             | maintain_aspect_ratio: 0     |
|    |                    |               |            |                    |             | input_dim: [1, 600, 800, 3]  |
|    |                    |               |            |                    |             | output_dim: [1, 227, 227, 3] |
| 2  | data_subtract_mean | subtract_mean | data_scale | data_subtract_mean | 1x227x227x3 |                              |
</pre> </div></div><!-- contents -->
</div><!-- doc-content -->
<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 -->
<!-- start footer part -->
<div id="nav-path" class="navpath" font-size:small;><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">
      <p align="right">
        80-NL315-14 A <br>
        MAY CONTAIN U.S. AND INTERNATIONAL EXPORT CONTROLLED INFORMATION
        <!--If the Controlled Distribution statement is to be included, uncomment below:-->
        <!--<b>Controlled Distribution - DO NOT COPY</b>-->
        <img class="footer" width:5%; alt="QTI Logo" src="images/QTI_Logo.png" />
      </p>
    </li>
  </ul>
</div>
</body>
</html>
