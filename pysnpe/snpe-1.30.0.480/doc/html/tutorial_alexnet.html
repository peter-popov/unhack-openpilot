<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-->
<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"></meta>
<meta http-equiv="X-UA-Compatible" content="IE=9"></meta>
<title>Snapdragon Neural Processing Engine SDK: Running the AlexNet Model</title>
<link href="tabs.css" rel="stylesheet" type="text/css"></link>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="autoEnterCurrentDate.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="is.css" rel="stylesheet" type="text/css" ></link>
<link href="custom.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Snapdragon Neural Processing Engine SDK
   <span id="projectnumber"></span></div>
   <div id="projectbrief">Reference Guide</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('tutorial_alexnet.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Running the AlexNet Model </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="overview_native_app"></a>
Overview</h1>
<p>The example C++ application in this tutorial is called <b>snpe-net-run</b>. It is a command line executable that executes a neural network using SNPE SDK APIs.</p>
<p>The required arguments to snpe-net-run are:</p><ul>
<li>A neural network model in the DLC file format</li>
<li>An input list file with paths to the input data.</li>
</ul>
<p>Optional arguments to snpe-net-run are:</p><ul>
<li>Choice of GPU or DSP runtime (default is CPU)</li>
<li>Output directory (default is ./output)</li>
<li>Show help description</li>
</ul>
<p>snpe-net-run creates and populates an output directory with the results of executing the neural network on the input data.</p>
<p><a class="anchor" id="fig_neural_network"></a>  <div style= text-align:left;><img src="images/neural_network.png" alt="SNPE" width="40%" height="40%"><br/><br/><b></b></div><br/> </p>
<p>The SNPE SDK provides Linux and Android binaries of <b>snpe-net-run</b> under</p><ul>
<li>$SNPE_ROOT/bin/x86_64-linux-clang</li>
<li>$SNPE_ROOT/bin/arm-android-clang6.0</li>
<li>$SNPE_ROOT/bin/aarch64-android-clang6.0</li>
<li>$SNPE_ROOT/bin/aarch64-linux-gcc4.9</li>
<li>$SNPE_ROOT/bin/arm-linux-gcc4.9sf</li>
<li>$SNPE_ROOT/bin/aarch64-oe-linux-gcc6.4</li>
<li>$SNPE_ROOT/bin/arm-oe-linux-gcc6.4hf</li>
</ul>
<h1><a class="anchor" id="tutorial_alexnet_prerequisites"></a>
Prerequisites</h1>
<ul>
<li>
The SNPE SDK has been set up following the <a class="el" href="setup.html">SNPE Setup</a> chapter. </li>
<li>
The <a class="el" href="tutorial_setup.html">Tutorials Setup</a> has been completed. </li>
<li>
Caffe is installed (see <a class="el" href="setup_caffe.html">Caffe &amp; Caffe2 Setup</a>) </li>
</ul>
<h1><a class="anchor" id="tutorial_alexnet_introduction"></a>
Introduction</h1>
<p>The AlexNet imagenet classification model is trained to classify images with 1000 labels. The examples below shows the steps required to execute a pretrained AlexNet model with <b>snpe-net-run</b> to classify a set of sample images.</p>
<h1><a class="anchor" id="tutorial_alexnet_run_on_linux_host"></a>
Run on Linux Host</h1>
<p>Go to the base location for the model and run <b>snpe-net-run</b></p>
<pre class="fragment">cd $SNPE_ROOT/models/alexnet
snpe-net-run --container dlc/bvlc_alexnet.dlc --input_list data/cropped/raw_list.txt
</pre><p>After snpe-net-run completes, verify that the results are populated in the $SNPE_ROOT/models/alexnet/output directory. There should be one or more .log files and several Result_X directories, each containing a <b>prob.raw</b> file.</p>
<p>One of the inputs is data/cropped/handicap_sign.raw and it was created from data/cropped/handicap_sign.jpg which looks like the following.</p>
<p><a class="anchor" id="fig_data_ex0_1"></a>  <div style= text-align:left;><img src="images/handicap_sign.jpg" alt="SNPE" width="30%" height="30%"><br/><br/><b></b></div><br/> </p>
<p>With this input file, snpe-net-run created the output file $SNPE_ROOT/models/alexnet/output/Result_0/prob.raw. It holds the output tensor data of 1000 probabilities for the 1000 categories. The element with the highest value represents the top classification. We can use a python script to interpret the classification results as follows.</p>
<pre class="fragment">python $SNPE_ROOT/models/alexnet/scripts/show_alexnet_classifications.py -i data/cropped/raw_list.txt \
                                                                         -o output/ \
                                                                         -l data/ilsvrc_2012_labels.txt
</pre><p>The output should look like the following, showing classification results for all the images.</p>
<pre class="fragment">Classification results
&lt;input_files_dir&gt;/trash_bin.raw     0.949348 412 ashcan, trash can, garbage can,
                                                 wastebin, ash bin, ash-bin, ashbin,
                                                 dustbin, trash barrel, trash bin

&lt;input_files_dir&gt;/plastic_cup.raw   0.749104 647 measuring cup
&lt;input_files_dir&gt;/chairs.raw        0.365685 831 studio couch, day bed
&lt;input_files_dir&gt;/handicap_sign.raw 0.101762 919 street sign
&lt;input_files_dir&gt;/notice_sign.raw   0.722708 458 brass, memorial tablet, plaque
</pre><p><b>Note:</b> The &lt;input_files_dir&gt; above maps to a path such as /local/mnt/workspace/XXX/snpe-x.y.z/models/alexnet/data/cropped/</p>
<p>The output shows the image was classified as "street sign" (index 919 of the labels) with a probability of 0.187978. Look at the rest of the output to see the model's classification on other images.</p>
<p><b>Binary data input</b></p>
<p>Note that the AlexNet image classification model does not accept jpg files as input. The model expects its input tensor dimension to be 227x227x3 as a float array, see <a class="el" href="image_input.html#input_image_layout">Input Images</a> for more detail. The scripts/setup_alexnet.py script performed a jpg to binary data conversion by calling scripts/create_alexnet_raws.py. The scripts are an example of how jpg images can be preprocessed to generate input for the AlexNet model.</p>
<h1><a class="anchor" id="tutorial_alexnet_run_on_android"></a>
Run on Android Target</h1>
<p><b>Select target architecture</b></p>
<p>SNPE provides Android binaries for armeabi-v7a and arm64-v8a architectures. For each architecture, there binaries are compiled with clang6.0 using libc++ STL implementation. The following shows the commands to select the desired binaries.</p>
<pre class="fragment"># architecture: armeabi-v7a - compiler: clang - STL: libc++
export SNPE_TARGET_ARCH=arm-android-clang6.0
export SNPE_TARGET_STL=libc++_shared.so

# architecture: arm64-v8a - compiler: clang - STL: libc++
export SNPE_TARGET_ARCH=aarch64-android-clang6.0
export SNPE_TARGET_STL=libc++_shared.so
</pre><p>For simplicity, this tutorial sets the target binaries to arm-android-clang6.0, which use libc++_shared.so, for commands on host and on target.</p>
<p><b>Push binaries to target</b></p>
<p>Push SNPE libraries and the prebuilt snpe-net-run executable to /data/local/tmp/snpeexample on the Android target.</p>
<pre class="fragment">export SNPE_TARGET_ARCH=arm-android-clang6.0
export SNPE_TARGET_STL=libc++_shared.so

adb shell "mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin"
adb shell "mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
adb shell "mkdir -p /data/local/tmp/snpeexample/dsp/lib"

adb push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL \
      /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib
adb push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so \
      /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib
adb push $SNPE_ROOT/lib/dsp/*.so \
      /data/local/tmp/snpeexample/dsp/lib
adb push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run \
      /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin
</pre><p><b>Set up enviroment variables</b></p>
<p>Set up the library path, the path variable, and the target architecture in adb shell to run the executable with the -h argument to see its description.</p>
<pre class="fragment">adb shell
export SNPE_TARGET_ARCH=arm-android-clang6.0
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib
export PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin
snpe-net-run -h
exit
</pre><p><b>Push model data to Android target</b></p>
<p>To execute the AlexNet classification model on your Android target follow these steps:</p>
<pre class="fragment">cd $SNPE_ROOT/models/alexnet
mkdir data/rawfiles &amp;&amp; cp data/cropped/*.raw data/rawfiles/
adb shell "mkdir -p /data/local/tmp/alexnet"
adb push data/rawfiles /data/local/tmp/alexnet/cropped
adb push data/target_raw_list.txt /data/local/tmp/alexnet
adb push dlc/bvlc_alexnet.dlc /data/local/tmp/alexnet
rm -rf data/rawfiles
</pre><p><b>Note:</b> It may take some time to push the AlexNet dlc file to your target.</p>
<h1><a class="anchor" id="tutorial_alexnet_run_on_android_cpu"></a>
Running on Android using CPU Runtime</h1>
<p>Run the Android C++ executable with the following commands:</p>
<pre class="fragment">adb shell
export SNPE_TARGET_ARCH=arm-android-clang6.0
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib
export PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin
cd /data/local/tmp/alexnet
snpe-net-run --container bvlc_alexnet.dlc --input_list target_raw_list.txt
exit
</pre><p>The executable will create the results folder: /data/local/tmp/alexnet/output. To pull the output:</p>
<pre class="fragment">adb pull /data/local/tmp/alexnet/output output_android
</pre><p>Check the classification results by running the interpret python script.</p>
<pre class="fragment">python scripts/show_alexnet_classifications.py -i data/target_raw_list.txt -o output_android/ \
                                               -l data/ilsvrc_2012_labels.txt
</pre><p>The output should look like the following, showing classification results for all the images.</p>
<pre class="fragment">Classification results
cropped/trash_bin.raw     0.949346 412 ashcan, trash can, garbage can, wastebin, ash bin,
                                       ash-bin, ashbin, dustbin, trash barrel, trash bin
cropped/plastic_cup.raw   0.749105 647 measuring cup
cropped/chairs.raw        0.365684 831 studio couch, day bed
cropped/handicap_sign.raw 0.101762 919 street sign
cropped/notice_sign.raw   0.722704 458 brass, memorial tablet, plaque</pre><h1><a class="anchor" id="tutorial_alexnet_run_on_android_gpu"></a>
Running on Android using GPU Runtime</h1>
<p>Try running on an Android target with the <b>--use_gpu</b> option as follows. By default, the GPU runtime runs in GPU_FLOAT32_16_HYBRID (math: full float and data storage: half float) mode. One could change the mode to GPU_FLOAT16 (math: half float and data storage: half float) using <b>&ndash;gpu_mode</b> option.</p>
<pre class="fragment">adb shell
export SNPE_TARGET_ARCH=arm-android-clang6.0
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib
export PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin
cd /data/local/tmp/alexnet
snpe-net-run --container bvlc_alexnet.dlc --input_list target_raw_list.txt --use_gpu
exit
</pre><p>Pull the output into an output_android_gpu directory.</p>
<pre class="fragment">adb pull /data/local/tmp/alexnet/output output_android_gpu
</pre><p>Again, we can run the interpret script to see the classification results.</p>
<pre class="fragment">python scripts/show_alexnet_classifications.py -i data/target_raw_list.txt \
                                               -o output_android_gpu/ \
                                               -l data/ilsvrc_2012_labels.txt
</pre><p>The output should look like the following, showing classification results for all the images.</p>
<pre class="fragment">Classification results
cropped/trash_bin.raw     0.948242 412 ashcan, trash can, garbage can, wastebin, ash bin,
                                       ash-bin, ashbin, dustbin, trash barrel, trash bin
cropped/plastic_cup.raw   0.747559 647 measuring cup
cropped/chairs.raw        0.363770 831 studio couch, day bed
cropped/handicap_sign.raw 0.101440 919 street sign
cropped/notice_sign.raw   0.720215 458 brass, memorial tablet, plaque</pre><p> Review the output for the classification results.</p>
<p>Classification results are identical to the run with CPU runtime, but there are differences in the probabilities associated with the output labels due to floating point precision differences. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 -->
<!-- start footer part -->
<div id="nav-path" class="navpath" font-size:small;><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">
      <p align="right">
        80-NL315-14 A <br>
        MAY CONTAIN U.S. AND INTERNATIONAL EXPORT CONTROLLED INFORMATION
        <!--If the Controlled Distribution statement is to be included, uncomment below:-->
        <!--<b>Controlled Distribution - DO NOT COPY</b>-->
        <img class="footer" width:5%; alt="QTI Logo" src="images/QTI_Logo.png" />
      </p>
    </li>
  </ul>
</div>
</body>
</html>
