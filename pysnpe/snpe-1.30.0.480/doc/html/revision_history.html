<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-->
<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"></meta>
<meta http-equiv="X-UA-Compatible" content="IE=9"></meta>
<title>Snapdragon Neural Processing Engine SDK: Revision History</title>
<link href="tabs.css" rel="stylesheet" type="text/css"></link>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="autoEnterCurrentDate.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="is.css" rel="stylesheet" type="text/css" ></link>
<link href="custom.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Snapdragon Neural Processing Engine SDK
   <span id="projectnumber"></span></div>
   <div id="projectbrief">Reference Guide</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('revision_history.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Revision History </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p> <p><table class="doxtable" width="100%">  <tr>  <th colspan="1"> Version </th> <th colspan="1"> Date </th> <th colspan="1"> Description </th>  </tr>     <tr> <td> 1.30.0 </td> <td> August 2019 </td> <td> Documentation has been added to reflect the new common converter command line options for input processing; Converters now propagate required batchnorm information for performing quantization optimizations; Support for the new bias correction quantization optimization which adjusts biases by analyzing float vs quantized activation errors and adjusting the model to compensate; ONNX converter now filters single input Concats as a no ops as SNPE didn’t support them; Converter input processing now uniformly handles different input types and encodings; ONNX converter now supports the ConvTranspose ‘output_padding’ attribute by adding an additional pad layer after the ConvTranspose op; Integrates the latest flatbuffer 1.11 library which brings speed improvements and options for model size reduction; GPU size limitations with the ArgMax op (when setting the keepDims op attribute to false) can be worked around by enabling CPU fallback; Fixed DSP error with MobileNet SSD on QCS403 and QCS405; Fixed the issue with partitioning of deconv layer in HTA; </td> </tr>  <tr> <td> 1.29.0 </td> <td> July 2019 </td> <td> Added support for dlc reorder tool;Optimization of HTA d32 conversions;Added tf space_to_depth op for SNPE CPU and DSP runtime;Benchmarking scripts enhanced for showing further break down of execution time, across various components;Added support for additional ONNX binary element-wise ops;Optimized deconv layer for improving performance;Fixed an issue related to runtime error in DSP runtime;Performance Optimization of SNPE GPU Runtime for Shufflenet V2 by using profiling level config </td> </tr>  <tr> <td> 1.28.0 </td> <td> June 2019 </td> <td> Added an optional argument to isRuntimeAvailable for the DSP runtime so that it doesn't activate the DSP; Allow UB_T8 and UB_FLOAT output for snpe-net-run; Added a new command line option for snpe-dlc-diff to check layer names; Updated the &ndash;dlc argument to &ndash;output_path for snpe-caffe-to-dlc to align with the ONNX converter; Added &ndash;dry_run argument to snpe-onnx-to-dlc to allow evaluation for successful conversion on an ONNX model; Added support for the gather op in the DSP runtime; Added support to convert the TF MobileNet-V1-FPN-SSD model; Fixed a memory leak in the DSP runtime that is seen when repeatedly loading and unloading a network; Addressed issues on V66 DSPs related to acquiring VTCM memory; Fixed an issue related to multiple inputs for the Caffe converter; Fixed an issue in the TF converter related to element-wise sun and the atrous parameter; Fixed an issue in the TF converter related to tf.crop_and_resize when there are only 2 inputs.; Fixed additional cases of uncaught exceptions with the aarch64-android-clang6.0 platform; </td> </tr>  <tr> <td> 1.27.0 </td> <td> May 2019 </td> <td> Added new APIs support for setting output tensor names to snpeBuilder and to fetch output tensor names for a given output layer name; Improved the peak memory usage with DLC v3 format; Fixed few issues with performance and runtime failures on DSP runtime; Fixed few issues and improved error handling for platform validator; Fixed the issues with Pooling and Instance norm layers of Tensorflow converter; Removed *-android-gcc4.9 platform support. This compiler has been retired for the Android NDK, so all support is transitioning to using Clang for Android; Removed arm-linux-gcc4.8hf platform. The development platform has been retired; </td> </tr>  <tr> <td> 1.26.0 </td> <td> Apr 2019 </td> <td> Added support for the ONNX Gather Op in the ONNX Converter and CPU runtime; Optimized DeConvolution Layer for the DSP runtime; Support for tf.nn.moments in the TF converter, CPU and DSP runtimes; Added TF Reflect Pad support for the DSP runtime; Add symmetric quantizer option in snpe-dlc-quantize; Add support for batch &gt; 1 when using the Scale Layer on the DSP runtime; Updated Platform Validator python script to be OS-independent; Added additional optimizations for HTA input conversion; </td> </tr>  <tr> <td> 1.25.0 </td> <td> Mar 2019 </td> <td> Updated DLC format to improve load time performance and memory consumption. Old DLCs will continue to work as is, but new DLCs generated from 1.25 will use the new format; Added support for optimized; MultiClassNms and ArgMax ops on DSP runtime; Added option to request larger memory allocations on the DSP for improved init time, at the expense of more memory use; Improved concurrency for multiple; SNPE objects running simultaneously on DSP; Improvements when using priority control on DSP; Added support for channel shuffle and ArgMax in the ONNX converter; Support multiple subnets within the AIP runtime; </td> </tr>  <tr> <td> 1.24.0 </td> <td> Feb 2019 </td> <td> Adding setProfilingLevel API support for AIP and CPU runtimes; Various stability issues on aip runtimes are addressed;Added support for Snapdragon 712;Support multi inputs and multiple outputs on each SNPE AIP’s subnet </td> </tr>  <tr> <td> 1.23.0 </td> <td> Jan 2019 </td> <td> Upgrade to Android NDK r17c to build SNPE; Improving initialization and de-initialization times; Various DSP timing fixes; Addressed some DSP concurrency edge cases that could impact output values; TF converter support for non max suppression, crop and resize Ops </td> </tr>  <tr> <td> 1.22.0 </td> <td> Nov 2018 </td> <td> Support for several new ops on DSP runtime; Upgrade to Android NDK r16b to build SNPE; setProfilingLevel API support in DSP runtime; Added new tool snpe-throughput-net-run </td> </tr>  <tr> <td> 1.21.0 </td> <td> Oct 2018 </td> <td> Tensorflow converter and CPU runtime support for various ops; DSP runtime support for Eltwise Realdiv and Square ops; GPU support for resize_align_corners layer </td> </tr>  <tr> <td> 1.20.0 </td> <td> Sep 2018 </td> <td> Support for QCS605 LE platform; NDK version upgrade to r14b; Tensorflow converter support for elementwise sqrt and softmax with dimension &gt; 2; Platform validation command line tool </td> </tr>  <tr> <td> 1.19.0 </td> <td> Aug 2018 </td> <td> ELU op support for Tensorflow/Onnx Converters and CPU/GPU runtimes; BoxWithNMSLimit and BBoxTransform ops support in caffe2 converter; Support for Caffe Power Layer in GPU </td> </tr>  <tr> <td> 1.18.0 </td> <td> Jul 2018 </td> <td> Support for pad and elementwise subtraction on GPU; ONNX converter support for shape and pad ops; Tensorflow converter support for additional ops </td> </tr>  <tr> <td> 1.17.0 </td> <td> Jun 2018 </td> <td> Support for Scale Layer in Caffe converter and DSP runtime, DSP support for batch&gt;1 and ChannelShuffle, Updated SDK examples for Inception v3 2016 model </td> </tr>  <tr> <td> 1.16.2 </td> <td> May 2018 </td> <td> Remove linkage to libstdc++.so in DSP loader libraries </td> </tr>  <tr> <td> 1.16.1 </td> <td> May 2018 </td> <td> Remove linkage to libstdc++.so, DSP runtime fixes, fix for 1D BatchNorm </td> </tr>  <tr> <td> 1.16.0 </td> <td> May 2018 </td> <td> Batch&gt;1 support (except DSP runtime); layer optimizations for DSP runtime; Caffe2 ChannelShuffle support (except DSP runtime) </td> </tr>  <tr> <td> 1.15.2 </td> <td> Mar 2018 </td> <td> Fix for GPU runtime memory leak and reshape to/from 1D </td> </tr>  <tr> <td> 1.15.1 </td> <td> Apr 2018 </td> <td> Fix for converter for instance normalization followed by scale </td> </tr>  <tr> <td> 1.15.0 </td> <td> Apr 2018 </td> <td> Support for instance normalization for Caffe and Caffe2, MobilenetSSD (Caffe) </td> </tr>  <tr> <td> 1.14.1 </td> <td> Mar 2018 </td> <td> Minor fixes </td> </tr>  <tr> <td> 1.14.0 </td> <td> Mar 2018 </td> <td> ONNX converter (alpha), multiple enhancements and fixes </td> </tr>  <tr> <td> 1.13.0 </td> <td> Feb 2018 </td> <td> GPU and DSP v65 performance improvements. GPU floating point 16 support. </td> </tr>  <tr> <td> 1.12.0 </td> <td> Jan 2018 </td> <td> Support for Android LLVM/libc++, MobilenetSSD (TensorFlow) </td> </tr>  <tr> <td> 1.10.1 </td> <td> Dec 2017 </td> <td> Fix a bug in the DSP runtime when using mixed userbuffer input types </td> </tr>  <tr> <td> 1.10.0 </td> <td> Dec 2017 </td> <td> Support for Mobilenet on DSP, enhanced DSP runtime, Snapdragon Flight Board, updates for UserBuffers </td> </tr>  <tr> <td> 1.8.0 </td> <td> Nov 2017 </td> <td> Mobilenet support on CPU, GPU, Support for Snapdragon 636 and Android 64 bit </td> </tr>  <tr> <td> 1.6.0 </td> <td> Oct 2017 </td> <td> Support for Snapdragon 450, minor updates and fixes </td> </tr>  <tr> <td> 1.4.0 </td> <td> Aug 2017 </td> <td> Support for Snapdragon 630, FasterRCNN and ADSP on AGL </td> </tr>  <tr> <td> 1.2.2 </td> <td> July 2017 </td> <td> QDN release </td> </tr>  <tr> <td> 1.2.0 </td> <td> June 2017 </td> <td> Beta Caffe2 Converter </td> </tr>  <tr> <td> 1.0.2 </td> <td> May 2017 </td> <td> Support for 820AGL platform, Snapdragon 660, and Compute DSP on Android </td> </tr>  <tr> <td> 1.0.1 </td> <td> Apr 2017 </td> <td> Documentation update only </td> </tr>  <tr> <td> 1.0 </td> <td> Apr 2017 </td> <td> </td> </tr>  </table></p>  </div></div><!-- contents -->
</div><!-- doc-content -->
<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 -->
<!-- start footer part -->
<div id="nav-path" class="navpath" font-size:small;><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">
      <p align="right">
        80-NL315-14 A <br>
        MAY CONTAIN U.S. AND INTERNATIONAL EXPORT CONTROLLED INFORMATION
        <!--If the Controlled Distribution statement is to be included, uncomment below:-->
        <!--<b>Controlled Distribution - DO NOT COPY</b>-->
        <img class="footer" width:5%; alt="QTI Logo" src="images/QTI_Logo.png" />
      </p>
    </li>
  </ul>
</div>
</body>
</html>
